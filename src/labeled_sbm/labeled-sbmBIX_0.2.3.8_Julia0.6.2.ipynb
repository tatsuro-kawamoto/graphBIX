{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "rc(\"text\",usetex =\"true\")\n",
    "\n",
    "function logsumexp(array)\n",
    "    array = vec(sort(array[:], by=abs, rev=true))\n",
    "    maxval = maximum(array)\n",
    "    for k = 1:length(array)\n",
    "        maxval - array[k] > 500 ? array[k] = maxval - 500 : continue\n",
    "    end\n",
    "    array[1] + log.(sum(exp.(array - vec(ones(1,length(array)))*array[1])))\n",
    "end\n",
    "\n",
    "function EM(Ntot,Larray,B,G,links,itrmax,BPconvthreshold,learning,priorlearning,dc,learningrate,REDfrac,assortativity,Omega)\n",
    "\n",
    "    function normalize_logprob(array)\n",
    "        arraylength = length(array)\n",
    "        for r = 1:arraylength\n",
    "            array[r] < log.(10^(-8.0)) ? array[r] = log.(10^(-8.0)) : continue\n",
    "        end\n",
    "        exp.(array -logsumexp(array)*vec(ones(1,arraylength)))\n",
    "    end\n",
    "\n",
    "    \n",
    "    function update_gr(PSI)\n",
    "        gr = mean(PSI,1)\n",
    "    end\n",
    "    \n",
    "    function update_h()\n",
    "        for alpha = 1:G\n",
    "            h[alpha,:] = sum( (degrees[:,alpha]*ones(1,B)).*(PSI*affinity[alpha]), 1) # 1-by-B vector for given alpha\n",
    "        end\n",
    "        return h\n",
    "    end\n",
    "    \n",
    "    function updatePSI()\n",
    "        for i = 1:Ntot\n",
    "            logPSIi = logunnormalizedMessage(i)\n",
    "            PSI[i,:] = normalize_logprob(logPSIi)\n",
    "        end\n",
    "        return PSI\n",
    "    end\n",
    "\n",
    "    function logunnormalizedMessage(i)\n",
    "        logmessages = zeros(1,B)\n",
    "        for s in nb[i]\n",
    "            indsi = sub2ind((Ntot,Ntot),s,i)\n",
    "            alpha = Int64(PSIcav[indsi][end])\n",
    "            logmessages += log.( degrees[i,alpha]*degrees[s,alpha]*reshape(PSIcav[indsi][1:end-1],(1,B))*affinity[alpha]*Ntot ) # Last Ntot is required to avoid underflow\n",
    "        end\n",
    "        \n",
    "        ext = zeros(1,B)\n",
    "        for alpha = 1:G\n",
    "            ext += degrees[i,alpha]*(h[alpha,:])'\n",
    "        end\n",
    "\n",
    "        logmessages += log.(gr) -ext\n",
    "\n",
    "        return vec(logmessages)\n",
    "    end\n",
    "\n",
    "    function BP()\n",
    "        conv = 0\n",
    "        for i in randperm(Ntot)\n",
    "            logPSIi = logunnormalizedMessage(i)\n",
    "            for j in nb[i]\n",
    "                indij = sub2ind((Ntot,Ntot),i,j)\n",
    "                indji = sub2ind((Ntot,Ntot),j,i)\n",
    "                alpha = Int64(PSIcav[indji][end])\n",
    "                PSIcav[indij][1:end-1] = logPSIi - log.( vec(degrees[i,alpha]*degrees[j,alpha]*(PSIcav[indji][1:end-1])'*affinity[alpha]*Ntot) ) # Last Ntot is required to avoid underflow\n",
    "                PSIcav[indij][1:end-1] = normalize_logprob(PSIcav[indij][1:end-1])\n",
    "            end\n",
    "\n",
    "            prev = PSI[i,:]/Ntot\n",
    "            logPSIi = logunnormalizedMessage(i) # new PSI with new PSIcav\n",
    "            PSI[i,:] = normalize_logprob(logPSIi)\n",
    "            conv += sum(abs.(PSI[i,:]/Ntot - prev))\n",
    "        end\n",
    "        return (conv, PSI)\n",
    "    end\n",
    "    \n",
    "    function update_affinity()\n",
    "        affinitynew = Dict()\n",
    "        for alpha = 1:G\n",
    "            affinitynew[alpha] = zeros(B,B)\n",
    "        end\n",
    "        for ij = 1:Ktot\n",
    "            (i,j) = (links[ij,1],links[ij,2])\n",
    "            if i > j\n",
    "                continue\n",
    "            end\n",
    "            indij = sub2ind((Ntot,Ntot),i,j)\n",
    "            indji = sub2ind((Ntot,Ntot),j,i)\n",
    "            alpha = Int64(PSIcav[indij][end])\n",
    "            PSIij = degrees[i,alpha]*degrees[j,alpha]*( (reshape(PSIcav[indij][1:end-1],(B,1))*reshape(PSIcav[indji][1:end-1],(1,B))).*(Ntot*affinity[alpha]) )\n",
    "            affinitynew[alpha] += PSIij/sum(PSIij) # sumPSIij\n",
    "        end\n",
    "        denom = zeros(G,B)\n",
    "        for i = 1:Ntot\n",
    "            for alpha = 1:G\n",
    "                denom[alpha,:] += degrees[i,alpha]*PSI[i,:]\n",
    "            end\n",
    "        end\n",
    "        for alpha = 1:G\n",
    "            affinity[alpha] = (affinitynew[alpha] + affinitynew[alpha]')./(reshape(denom[alpha,:],(B,1))*reshape(denom[alpha,:],(1,B))) # no need for symmetrization of affinitynew because for ij = 1:Ktot is taken over (i, j) & (j, i).\n",
    "            affinity[alpha][affinity[alpha].<10^(-8.0)] = 10^(-8.0) # underflow cut-off\n",
    "        end\n",
    "        \n",
    "        if REDfrac != 0\n",
    "            affinity[G] = (1/Ktot)*ones(B,B)# RED edges (Coefficients are not important.)\n",
    "        end\n",
    "        \n",
    "        return affinity\n",
    "    end\n",
    "\n",
    "    function freeenergy()\n",
    "        sumlogZi = 0\n",
    "        for i = 1:Ntot\n",
    "            sumlogZi += logsumexp(logunnormalizedMessage(i))\n",
    "        end\n",
    "        \n",
    "        logZijs = zeros(Ltot)\n",
    "        CVGPs = zeros(Ltot)\n",
    "        CVGTs = zeros(Ltot)\n",
    "        CVMAPs = zeros(Ltot)\n",
    "        cnt = 0\n",
    "        for ij = 1:Ktot\n",
    "            (i,j) = (links[ij,1],links[ij,2])\n",
    "            if i < j\n",
    "                continue\n",
    "            end\n",
    "            indij = sub2ind((Ntot,Ntot),i,j)\n",
    "            indji = sub2ind((Ntot,Ntot),j,i)\n",
    "            alpha = Int64(PSIcav[indij][end])\n",
    "            cnt += 1\n",
    "            \n",
    "            # log Z^{ij}\n",
    "            Zij = 0\n",
    "            for r = 1:B\n",
    "            for s = 1:B\n",
    "                    Zij += degrees[i,alpha]*degrees[j,alpha]*affinity[alpha][r,s]*PSIcav[indij][r]*PSIcav[indji][s]\n",
    "            end\n",
    "            end\n",
    "            logZijs[cnt] = log.(Zij) # calculate using Crs = Ntot*affinity, instead of affinity, to avoid underflow.\n",
    "            \n",
    "            # Gibbs prediction error\n",
    "            CVGPij = 0\n",
    "            for r = 1:B\n",
    "            for s = 1:B\n",
    "                    CVGPij += PSIcav[indij][r]*PSIcav[indji][s]*log.(degrees[i,alpha]*degrees[j,alpha]*affinity[alpha][r,s])\n",
    "            end\n",
    "            end\n",
    "            CVGPs[cnt] = CVGPij\n",
    "            \n",
    "            # Gibbs training error\n",
    "            CVGTij = 0\n",
    "            for r = 1:B\n",
    "            for s = 1:B\n",
    "                    CVGTij += PSIcav[indij][r]*PSIcav[indji][s]*(degrees[i,alpha]*degrees[j,alpha]*affinity[alpha][r,s])*log.(degrees[i,alpha]*degrees[j,alpha]*affinity[alpha][r,s])/Zij\n",
    "            end\n",
    "            end\n",
    "            CVGTs[cnt] = CVGTij\n",
    "            \n",
    "            # MAP estimate\n",
    "            (MAPij, s) = findmax(PSIcav[indij][1:end-1])\n",
    "            (MAPji, t) = findmax(PSIcav[indji][1:end-1])\n",
    "            CVMAPs[cnt] = log.(degrees[i,alpha]*degrees[j,alpha]*affinity[alpha][s,t])\n",
    "        end\n",
    "        \n",
    "        FE = -(sumlogZi - sum(logZijs) )/Ntot - Ltot/Ntot\n",
    "        CVBayes = 1-sum(logZijs)/Ltot\n",
    "        CVGP = 1-sum(CVGPs)/Ltot\n",
    "        CVGT = 1-sum(CVGTs)/Ltot\n",
    "        CVMAP = 1-sum(CVMAPs)/Ltot\n",
    "        varCVBayes = var(logZijs)\n",
    "        varCVGP = var(CVGPs)\n",
    "        varCVGT = var(CVGTs)\n",
    "        varCVMAP = var(CVMAPs)\n",
    "\n",
    "        return (FE, CVBayes, CVGP, CVGT, CVMAP, varCVBayes, varCVGP, varCVGT, varCVMAP)\n",
    "    end   \n",
    "    \n",
    "\n",
    "# initial state ########\n",
    "    cnv = false\n",
    "    itrnum = 0\n",
    "    Ktot = size(links,1)\n",
    "    Ltot = Int64(0.5*size(links,1))\n",
    "    cm = 2*Larray/Ntot\n",
    "    inds = sub2ind((Ntot,Ntot),links[:,1],links[:,2])\n",
    "    \n",
    "    A = sparse(links[:,1],links[:,2],links[:,3],Ntot,Ntot)\n",
    "    degrees = zeros(Int64,Ntot,G)\n",
    "    # neighboring vertices --------\n",
    "    nb = Array[]\n",
    "    row = rowvals(A)\n",
    "    for j = 1:Ntot\n",
    "        for i in nzrange(A,j)\n",
    "            alpha = A[row[i],j]\n",
    "            degrees[j,alpha] += 1\n",
    "        end\n",
    "        push!(nb,Int64[row[i] for i in nzrange(A,j)])\n",
    "    end\n",
    "    # ----------------------------------\n",
    "    #degrees = degrees/maximum(degrees) # modify the overall factor in order to avoid underflow.\n",
    "    if dc == false\n",
    "        degrees = ones(Int64,Ntot,G) #### Remove degree-correction #######\n",
    "    end\n",
    "    \n",
    "\n",
    "    affinity = Dict()\n",
    "    deltacinit = zeros(G)\n",
    "    if REDfrac == 0\n",
    "        dc == false ? Norm = Ntot : Norm = Ktot\n",
    "        for k =1:G\n",
    "            if assortativity[k] == \"a\"\n",
    "                deltacinit[k] = 0.99*cm[k]/Omega\n",
    "            elseif assortativity[k] == \"d\"\n",
    "                deltacinit[k] = -0.99*cm[k]/(1-Omega)\n",
    "            end\n",
    "            affinity[k] = ( (cm[k]-deltacinit[k]*Omega)*ones(B,B) + deltacinit[k]*eye(B) )/Norm\n",
    "        end        \n",
    "    else\n",
    "        dc == false ? Norm = Ntot : Norm = Ktot\n",
    "        for k =1:G-1\n",
    "            if assortativity[k] == \"a\"\n",
    "                deltacinit[k] = 0.99*cm[k]/Omega\n",
    "            elseif assortativity[k] == \"d\"\n",
    "                deltacinit[k] = -0.99*cm[k]/(1-Omega)\n",
    "            else\n",
    "                deltacinit[k] = 0 # neutral\n",
    "            end\n",
    "            affinity[k] = ( (cm[k]-deltacinit[k]*Omega)*ones(B,B) + deltacinit[k]*eye(B) )/Norm\n",
    "        end        \n",
    "        affinity[G] = ( cm[G]*ones(B,B) )/Norm\n",
    "    end\n",
    "            \n",
    "    gr = ones(1,B)/B # initial prior distribution\n",
    "    h = zeros(G,B)\n",
    "    PSIcav = Dict()\n",
    "    for ij = 1:size(links,1) #ind in inds\n",
    "        PSIcav[inds[ij]] = rand(1,B)\n",
    "        PSIcav[inds[ij]] = PSIcav[inds[ij]]/sum(PSIcav[inds[ij]])\n",
    "        PSIcav[inds[ij]] = hcat(PSIcav[inds[ij]], links[ij,3]) # last column indicates the edge label.\n",
    "    end\n",
    "    PSI = zeros(Ntot,B)\n",
    "    PSI = updatePSI()\n",
    "    h = update_h()\n",
    "    FE = 0\n",
    "    CVBayes = 0\n",
    "    CVGP = 0\n",
    "    CVGT = 0\n",
    "    CVMAP = 0\n",
    "    varCVBayes = 0\n",
    "    varCVGP = 0\n",
    "    varCVGT = 0\n",
    "    varCVMAP = 0\n",
    "################\n",
    "    for itr = 1:itrmax\n",
    "        h = update_h()\n",
    "        (BPconv, PSI) = BP()\n",
    "        if priorlearning == true\n",
    "            gr = learningrate*update_gr(PSI) + (1 - learningrate)*gr\n",
    "        end\n",
    "        if learning == true\n",
    "            affinityupdated = update_affinity()\n",
    "            for alpha = 1:G\n",
    "                affinity[alpha] = learningrate*affinityupdated[alpha] + (1 - learningrate)*affinity[alpha]\n",
    "            end\n",
    "        end\n",
    "        if BPconv < BPconvthreshold\n",
    "            println(\"converged! ^_^: itr = $(itr)\")\n",
    "            cnv = true\n",
    "            itrnum = itr\n",
    "            break\n",
    "        elseif itr == itrmax\n",
    "            if isnan(maximum(gr)) == true || maximum(PSI) == Inf\n",
    "                println(\"overflow : Use different initial partition or modify upper bound of the affinity matrix.\")\n",
    "            else\n",
    "                println(\"NOT converged: residual = $(Float16(BPconv))\")\n",
    "            end            \n",
    "        end\n",
    "    end\n",
    "\n",
    "    (FE, CVBayes, CVGP, CVGT, CVMAP, varCVBayes, varCVGP, varCVGT, varCVMAP) = freeenergy()\n",
    "    \n",
    "    return (gr,affinity,PSI,FE,CVBayes,CVGP,CVGT,CVMAP,varCVBayes,varCVGP,varCVGT,varCVMAP,cnv,itrnum)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################\n",
    "# Graph Trimming\n",
    "################################################\n",
    "function labeledsimplegraph(links)\n",
    "    # undirected simple graph (bidirected edges): \n",
    "    labels = unique(links[:,3])\n",
    "    sort!(labels, rev=false) # This is for the case the labels have values like -1.\n",
    "    for ij = 1:size(links,1)\n",
    "        links[ij,3] = find(labels.==links[ij,3])[1]\n",
    "    end\n",
    "\n",
    "    links = vcat(links,hcat(links[:,2],links[:,1],links[:,3])) # bidirected\n",
    "    links = unique(links,1)\n",
    "    # remove self-loops\n",
    "    boolean = trues(size(links,1))\n",
    "    for i = 1:size(links,1)\n",
    "        links[i,1] == links[i,2] ? boolean[i] = false : continue\n",
    "    end\n",
    "    links = links[boolean,:]\n",
    "    \n",
    "    return links\n",
    "end\n",
    "\n",
    "function DFS(nb,root)\n",
    "    visited = Int64[]\n",
    "    stack = push!(Int64[],root)\n",
    "    while !isempty(stack)\n",
    "        node = pop!(stack)\n",
    "        if node in visited\n",
    "            continue\n",
    "        else\n",
    "            push!(visited,node)\n",
    "            append!(stack,filter(x->!(x in visited), nb[node]))\n",
    "            stack = unique(stack)\n",
    "        end\n",
    "    end\n",
    "    return visited\n",
    "end\n",
    "\n",
    "function LinksConnected(links,Ntotinput,cc)\n",
    "    cc = sort(cc)\n",
    "    t = 1\n",
    "    defects = Int64[]\n",
    "    ndef = 0\n",
    "    for i = 1:Ntotinput\n",
    "        if t <= length(cc)\n",
    "            if i == cc[t]\n",
    "                t += 1\n",
    "                continue\n",
    "            end\n",
    "        end\n",
    "        ndef += 1\n",
    "        push!(defects,i) # ndef = # of defect nodes\n",
    "    end\n",
    "    Ntot = Ntotinput - ndef\n",
    "    #---------------------------------------------------\n",
    "    \n",
    "    # links of connected component ------------\n",
    "    boolean = trues(size(links,1))\n",
    "    for u = 1:size(links,1)\n",
    "        links[u,1] in cc || links[u,2] in cc ? continue : boolean[u] = false # For undirected(bidirected) case, links[u,1] in cc is enough.\n",
    "    end\n",
    "    links = links[boolean,:]\n",
    "    #----------------------------------------------------\n",
    "    \n",
    "    for u = 1:size(links,1)\n",
    "        links[u,1] -= countnz(defects.<links[u,1])\n",
    "        links[u,2] -= countnz(defects.<links[u,2])\n",
    "    end\n",
    "    \n",
    "    return (Ntot,links)\n",
    "end\n",
    "################################################\n",
    "# END: Graph Trimming\n",
    "################################################\n",
    "\n",
    "\n",
    "######################\n",
    "# Prediction error for q = 1\n",
    "######################\n",
    "function UniformGraphError(links,Ntot,Larray,dc,G,Ltot,REDfrac)\n",
    "    nullerror = 0\n",
    "    REDfrac != 0 ? Pas = Larray[1:G-1]/sum(Larray[1:G-1]) : Pas = Larray/sum(Larray)\n",
    "    entropy = sum([-Pa*log.(Pa) for Pa in Pas])\n",
    "\n",
    "    if dc == true\n",
    "        A = sparse(links[:,1],links[:,2],links[:,3],Ntot,Ntot)\n",
    "        degrees = zeros(Int64,Ntot,G)\n",
    "        # neighboring vertices --------\n",
    "        row = rowvals(A)\n",
    "        for j = 1:Ntot\n",
    "            for i in nzrange(A,j)\n",
    "                alpha = A[row[i],j]\n",
    "                degrees[j,alpha] += 1\n",
    "            end\n",
    "        end\n",
    "        # ----------------------------------\n",
    "\n",
    "        REDfrac != 0 ? Gmax = G-1 : Gmax = G\n",
    "        for alpha = 1:Gmax\n",
    "            for di in degrees[:,alpha]\n",
    "                if di > 0\n",
    "                    nullerror += di*log.(di)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        nullerror = 1 - nullerror/Ltot - entropy + log.(2*Ltot)\n",
    "    else\n",
    "        nullerror = 1 + entropy - log.(2*Ltot/(Ntot^2))\n",
    "    end\n",
    "    \n",
    "    return nullerror\n",
    "end\n",
    "\n",
    "######################\n",
    "######################\n",
    "\n",
    "\n",
    "######################\n",
    "# RED\n",
    "######################\n",
    "function RandomEdgeDiscarding(Ntot,labeledlinks,G,Larray,REDalpha,REDfrac)\n",
    "    undlabeledlinks = labeledlinks[ (labeledlinks[:,1]-labeledlinks[:,2]) .> 0,:]\n",
    "    REDlinks = undlabeledlinks[undlabeledlinks[:,3].==REDalpha,:]\n",
    "    nonREDlinks = undlabeledlinks[undlabeledlinks[:,3].!=REDalpha,:]\n",
    "\n",
    "    neutralkey = shuffle(collect(1:size(REDlinks,1)))[1:ceil(Int64,REDfrac*size(REDlinks,1))]\n",
    "    for k in neutralkey\n",
    "        REDlinks[k,3] = G+1\n",
    "    end\n",
    "    undlabeledlinksRenewed = vcat(REDlinks,nonREDlinks) # undirected links\n",
    "    labeledlinksRenewed = vcat(undlabeledlinksRenewed,hcat(undlabeledlinksRenewed[:,2],undlabeledlinksRenewed[:,1],undlabeledlinksRenewed[:,3])) # bidirected\n",
    "    \n",
    "    Larray[REDalpha] = Larray[REDalpha] - size(neutralkey,1)\n",
    "    push!(Larray,size(neutralkey,1))\n",
    "    println(Larray)\n",
    "    \n",
    "    return (labeledlinksRenewed,Larray)\n",
    "end\n",
    "######################\n",
    "# END: RED\n",
    "######################\n",
    "\n",
    "\n",
    "function degreeprofile(links,Ntot)\n",
    "    Ktot = size(links,1)\n",
    "    A = sparse(links[:,1],links[:,2],ones(Int64,Ktot),Ntot,Ntot)\n",
    "    degrees = sum(A,2)\n",
    "    maxdegree = maximum(degrees)\n",
    "    profile = zeros(Int64,maxdegree)\n",
    "    for deg in degrees\n",
    "        profile[deg] += 1\n",
    "    end\n",
    "    println(profile)\n",
    "    \n",
    "    return degrees\n",
    "end\n",
    "\n",
    "\n",
    "###############################\n",
    "# Functions for plots\n",
    "###############################\n",
    "\n",
    "function RelabelPSI(PSIoptprev,groptprev,affinityoptprev,G)\n",
    "    B = length(groptprev)\n",
    "    PSIoptnew = zeros(size(PSIoptprev))\n",
    "    groptnew = zeros(size(groptprev))\n",
    "    affinityoptnew = Dict()\n",
    "    for alpha = 1:G\n",
    "        affinityoptnew[alpha] = zeros(B,B)\n",
    "    end\n",
    "    \n",
    "    # SORT ##############################\n",
    "    # Sort based on the total prob.: \n",
    "    # ind = sortperm(vec(sum(PSIoptprev,1)),rev=true)\n",
    "\n",
    "    # Sort based on the cluster sizes: \n",
    "    hist = zeros(Int64,B)\n",
    "    for i = 1:size(PSIoptprev,1)\n",
    "        bl = findmax(PSIoptprev[i,:])[2]\n",
    "        hist[bl] += 1\n",
    "    end\n",
    "    ind = sortperm(vec(hist),rev=true)\n",
    "    ####################################\n",
    "    \n",
    "    for k = 1:B\n",
    "        PSIoptnew[:,k] = PSIoptprev[:,ind[k]]\n",
    "        groptnew[k] = groptprev[ind[k]]\n",
    "        for l = 1:B\n",
    "            for alpha = 1:G\n",
    "                affinityoptnew[alpha][k,l] = affinityoptprev[alpha][ind[k],ind[l]]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return (PSIoptnew,groptnew,affinityoptnew)\n",
    "end\n",
    "\n",
    "# Alluvial diagram: smap file generator //////////////////////////////\n",
    "function AlluvialDiagram(B,block,maxPSIval,nodeids)\n",
    "    significant = 0.9\n",
    "    Ntot = size(maxPSIval,1)\n",
    "    stralluvial = \"partition$(B).smap\"\n",
    "    fpalluvial = open(stralluvial,\"w\")\n",
    "    \n",
    "    modules = zeros(Int64,Ntot,3) # [node num., block label, significance]\n",
    "    modules[:,1] = nodeids #collect(1:Ntot)\n",
    "    modules[:,2] = block\n",
    "    modules = sortrows(modules, by=x->x[2])\n",
    "    \n",
    "    trueB = 0\n",
    "    labelprev = 0\n",
    "    moduleindices = AbstractString[]\n",
    "    for k = 1:Ntot\n",
    "        if modules[k,2] != labelprev\n",
    "            trueB += 1\n",
    "            labelprev = modules[k,2] # modules[k,2] may not be successive, e.g. 1 1 3 3 4 4 ...\n",
    "            push!(moduleindices, \"$(modules[k,1]),...\")\n",
    "        end\n",
    "        modules[k,2] = trueB\n",
    "        #maxPSIval[modules[k,1]]>significant ? modules[k,3] = 1 : continue        \n",
    "        maxPSIval[find(nodeids.==modules[k,1])[1]]>significant ? modules[k,3] = 1 : continue        \n",
    "    end\n",
    "\n",
    "    write(fpalluvial, \"*Undirected\\n\")\n",
    "    write(fpalluvial, \"*Modules $(trueB)\\n\")\n",
    "    for md = 1:trueB\n",
    "        write(fpalluvial, \"\"\"$(md) \"$(moduleindices[md])\" $(Float16(0.1/trueB)) $(Float16(0.01/trueB))\\n\"\"\")\n",
    "    end\n",
    "    write(fpalluvial, \"*Insignificants 0\\n\")\n",
    "    write(fpalluvial, \"*Nodes $(Ntot)\\n\")\n",
    "    sublabel = 0\n",
    "    labelprev = 0\n",
    "    for k = 1:Ntot\n",
    "        modules[k,2] == labelprev ? sublabel += 1 : sublabel = 1\n",
    "        labelprev = modules[k,2]\n",
    "        if modules[k,3] == 1\n",
    "            write(fpalluvial, \"\"\"$(modules[k,2]):$(sublabel) \"Node $(modules[k,1])\" $(Float16(0.1/Ntot))\\n\"\"\")\n",
    "        else\n",
    "            write(fpalluvial, \"\"\"$(modules[k,2]);$(sublabel) \"Node $(modules[k,1])\" $(Float16(0.1/Ntot))\\n\"\"\")\n",
    "        end\n",
    "    end\n",
    "    write(fpalluvial, \"*Links $(trueB^2)\\n\")\n",
    "    for s = 1:trueB\n",
    "    for t = 1:trueB\n",
    "            write(fpalluvial, \"$(s) $(t) $(Float16(0.1/trueB^2))\\n\")\n",
    "    end\n",
    "    end\n",
    "    \n",
    "    close(fpalluvial)\n",
    "end\n",
    "\n",
    "\n",
    "function AssignmentsWithSignificance(B,block,maxPSIval,nodeids)\n",
    "    Ntot = size(maxPSIval,1)\n",
    "    strSignificance = \"AssignmentsWithSignificance_partition$(B).txt\"\n",
    "    fpSignificance = open(strSignificance,\"w\")\n",
    "    \n",
    "    modules = zeros(Float64,Ntot,3) # [node num., block label]\n",
    "    modules[:,1] = nodeids #collect(1:Ntot)\n",
    "    modules[:,2] = block\n",
    "    modules[:,3] = maxPSIval\n",
    "    modules = sortrows(modules, by=x->x[2])\n",
    "    \n",
    "    trueB = 0\n",
    "    labelprev = 0\n",
    "    for k = 1:Ntot\n",
    "        if modules[k,2] != labelprev\n",
    "            trueB += 1\n",
    "            labelprev = modules[k,2] # modules[k,2] may not be successive, e.g. 1 1 3 3 4 4 ...\n",
    "        end\n",
    "        modules[k,2] = trueB\n",
    "        write(fpSignificance, \"$(Int64(modules[k,1])) $(Int64(modules[k,2])) $(modules[k,3])\\n\")\n",
    "    end\n",
    "    \n",
    "    close(fpSignificance)\n",
    "end\n",
    "\n",
    "function AssignmentProbs(B,nodeids,PSIopt)\n",
    "    strProb = \"ProbDistribution_partition$(B).txt\"\n",
    "    fpProb = open(strProb,\"w\")\n",
    "\n",
    "    Ntot = size(PSIopt,1)\n",
    "    for k = 1:Ntot\n",
    "        PSIoptstr = \"\"\n",
    "        for i = 1:B\n",
    "            PSIoptstr *= \" $(PSIopt[k,i])\"\n",
    "        end\n",
    "        write(fpProb, \"$(nodeids[k])$(PSIoptstr)\\n\")\n",
    "    end\n",
    "    \n",
    "    close(fpProb)\n",
    "end\n",
    "\n",
    "\n",
    "function PlotAssessments(x,y0,y1,y1error,y2,y2error,y3,y3error,y4,y4error,dataset)\n",
    "    #Bmax = size(x,1) + 1\n",
    "    Bmin = minimum(x)\n",
    "    Bmax = maximum(x)\n",
    "    \n",
    "    fig = figure(\"plot_$(dataset)\",figsize=(9,3))\n",
    "    subplots_adjust(hspace=0.5,wspace=0.3)\n",
    "\n",
    "    # 1st fig --------\n",
    "    subplot(121)\n",
    "    p = plot(x,y0,color=\"0.4\",linestyle=\"-\",marker=\"8\",markeredgecolor=\"None\",markersize=8,label=\"Bethe free energy\")\n",
    "    ax = gca()\n",
    "    font1 = Dict(\"color\"=>\"k\",\"weight\"=>\"normal\")\n",
    "    ylabel(\"Bethe free energy\",fontdict=font1)\n",
    "    setp(ax[:get_yticklabels](),color=\"0.2\") # Y Axis font formatting\n",
    "    xlabel(L\"Number of clusters $\\mathit{q}$\",fontdict=font1)\n",
    "    ax[:set_xlim](Bmin-0.2,Bmax+0.2)\n",
    "    Mx = matplotlib[:ticker][:MultipleLocator](1) # Define interval\n",
    "    ax[:xaxis][:set_major_locator](Mx) # Set interval \n",
    "\n",
    "    # 2nd fig --------\n",
    "    subplot(122)\n",
    "    p = plot(x,y2,color=\"#27AE60\",linestyle=\"-\",linewidth=2,marker=\"^\",markersize=8,markerfacecolor=\"white\",markeredgecolor=\"#27AE60\",markeredgewidth=1.5,zorder=10,label=\"EGP\")\n",
    "    p = fill_between(x,vec(y2-y2error),vec(y2+y2error),color=\"#2ECC71\",alpha=0.7,edgecolor=\"None\",zorder=9)\n",
    "    p = plot(x,y1,color=\"#C0392B\",linestyle=\"-\",linewidth=2,marker=\"o\",markersize=7,markerfacecolor=\"white\",markeredgecolor=\"#C0392B\",markeredgewidth=1.5,zorder=8,label=\"EBayes\")\n",
    "    p = fill_between(x,vec(y1-y1error),vec(y1+y1error),color=\"#E74C3C\",alpha=0.7,edgecolor=\"None\",zorder=7)\n",
    "    p = plot(x,y3,color=\"#2980B9\",linestyle=\"-\",linewidth=2,marker=\"D\",markersize=7,markerfacecolor=\"white\",markeredgecolor=\"#2980B9\",markeredgewidth=1.5,zorder=6,label=\"EGT\")\n",
    "    p = fill_between(x,vec(y3-y3error),vec(y3+y3error),color=\"#3498DB\",alpha=0.7,edgecolor=\"None\",zorder=5)\n",
    "    p = plot(x,y4,color=\"#F39C12\",linestyle=\"-\",linewidth=2,marker=\"s\",markersize=7,markerfacecolor=\"white\",markeredgecolor=\"#F39C12\",markeredgewidth=1.5,zorder=4,label=\"EMAP\")\n",
    "    p = fill_between(x,vec(y4-y4error),vec(y4+y4error),color=\"#F1C40F\",alpha=0.7,edgecolor=\"None\",zorder=3)\n",
    "    ax = gca()\n",
    "    ax[:set_xlim](Bmin-0.2,Bmax+0.2)\n",
    "#    setp(ax[:get_xticklabels](),visible=false) # Disable x tick labels\n",
    "    xlabel(L\"Number of clusters $\\mathit{q}$\",fontdict=font1)\n",
    "    Mx = matplotlib[:ticker][:MultipleLocator](1) # Define interval\n",
    "    ax[:xaxis][:set_major_locator](Mx) # Set interval \n",
    "    font1 = Dict(\"color\"=>\"k\")\n",
    "    ylabel(\"Prediction/training error\",fontdict=font1)\n",
    "    setp(ax[:get_yticklabels](),color=\"k\") # Y Axis font formatting\n",
    "\n",
    "    #fig[:canvas][:draw]() # Update the figure\n",
    "    suptitle(dataset,fontdict=font1)\n",
    "    savefig(\"assessment_$(dataset).pdf\",bbox_inches=\"tight\",pad_inches=0.1)\n",
    "end\n",
    "\n",
    "\n",
    "function grCrsMatrices(grDictbb,CrsDictbb)\n",
    "    B = length(grDictbb)\n",
    "    Binmax = 50\n",
    "    grCrsMatrix = zeros(Binmax,Binmax)\n",
    "    binsizes = floor(Int64,Binmax*grDictbb)\n",
    "    offsetr = 0\n",
    "    for r = 1:B\n",
    "        offsets = 0\n",
    "        for s = 1:B\n",
    "            if r == B && s < B\n",
    "                grCrsMatrix[offsetr+1:Binmax,offsets+1:offsets+binsizes[s]] = CrsDictbb[r,s]\n",
    "            elseif r < B && s == B\n",
    "                grCrsMatrix[offsetr+1:offsetr+binsizes[r],offsets+1:Binmax] = CrsDictbb[r,s]\n",
    "            elseif r == B && s == B\n",
    "                grCrsMatrix[offsetr+1:Binmax,offsets+1:Binmax] = CrsDictbb[r,s]\n",
    "            else\n",
    "                grCrsMatrix[offsetr+1:offsetr+binsizes[r],offsets+1:offsets+binsizes[s]] = CrsDictbb[r,s]\n",
    "            end\n",
    "            offsets += binsizes[s]\n",
    "        end\n",
    "        offsetr += binsizes[r]\n",
    "    end\n",
    "    return grCrsMatrix\n",
    "end\n",
    "\n",
    "\n",
    "function PlotAffinityMatrixLBM(Bsize,grDict,affinityDict,dataset,REDfrac)\n",
    "    plt = PyPlot\n",
    "    fig=plt.figure(figsize=(2*Bsize, 4))\n",
    "    G = length(affinityDict[1])\n",
    "    REDfrac == 0 ? maxk = G : maxk = G-1# Last index is for the affinity matrix of the RED edges.\n",
    "    for k = 1:maxk\n",
    "        for bb = 1:Bsize\n",
    "            ax = fig[:add_subplot](maxk,Bsize,bb+(k-1)*Bsize) # G-by-Bsize\n",
    "            grCrsMatrix = grCrsMatrices(grDict[bb],affinityDict[bb][k])\n",
    "            plt.imshow(grCrsMatrix,interpolation=\"nearest\",cmap=ColorMap(\"Blues\"))\n",
    "            setp(ax[:get_xticklabels](),visible=false) # Disable x tick labels\n",
    "            setp(ax[:get_yticklabels](),visible=false) # Disable y tick labels\n",
    "        end\n",
    "    end\n",
    "    #    plt.colorbar() # skip this because the sizes of the plots will be unbalanced: matplotlib function seems to be required to cure this.\n",
    "    fig[:canvas][:draw]() # Update the figure\n",
    "    savefig(\"structures_$(dataset).pdf\",bbox_inches=\"tight\",pad_inches=0.1)\n",
    "end\n",
    "\n",
    "\n",
    "function PlotCumulativeFEdistribution(Bsize,FEsDict,dataset)\n",
    "    plt = PyPlot\n",
    "    fig=plt.figure(figsize=(3*Bsize, 3))\n",
    "    subplots_adjust(hspace=0,wspace=0.3)\n",
    "    for bb = 1:Bsize\n",
    "        ax = fig[:add_subplot](1,Bsize,bb)\n",
    "        f = sort(vec(FEsDict[bb]))\n",
    "        cdfarray = zeros(length(f),2)\n",
    "        val = 0\n",
    "        for y in f\n",
    "            val += 1\n",
    "            cdfarray[val,1] = y\n",
    "            cdfarray[val,2] = val\n",
    "        end\n",
    "\n",
    "        scatter(cdfarray[:,1],cdfarray[:,2],alpha=0.6)\n",
    "        setp(ax[:get_xticklabels](),fontsize=\"xx-small\") # Disable x tick labels\n",
    "#        xlabel(\"\")\n",
    "#        ylabel(\"\")\n",
    "        grid(\"on\")\n",
    "    end\n",
    "    axis(\"tight\")\n",
    "    fig[:canvas][:draw]() # Update the figure\n",
    "    savefig(\"FE_CDF_$(dataset).pdf\",bbox_inches=\"tight\",pad_inches=0.1)\n",
    "end\n",
    "\n",
    "###############################\n",
    "# END: Functions for plots\n",
    "###############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############\n",
    "##############\n",
    "# MAIN ########\n",
    "##############\n",
    "##############\n",
    "\n",
    "dataset = \"labeledSBM\"\n",
    "strdataset = \"labeledSBMedgelist_Nblock=[300,300,300]_c=[5,3]_X=[0.1,0.9]_1.txt\"\n",
    "Ltotinput = countlines(open( strdataset, \"r\" ))\n",
    "fpmeta = open(\"summary_$(dataset).txt\",\"w\")\n",
    "write(fpmeta, \"dataset: $(strdataset)\\n\\n\")\n",
    "open( strdataset, \"r\" ) do fp\n",
    "    cnt = 0\n",
    "    nodeids = Int64[]\n",
    "    for line in eachline( fp )\n",
    "    cnt += 1\n",
    "        line = rstrip(line, '\\n')\n",
    "        u = split(line, \" \")\n",
    "        #u = split(line, \"\\t\")\n",
    "        u1 = parse(Int64,u[1]) # convert string to number\n",
    "        u2 = parse(Int64,u[2])\n",
    "        push!(nodeids,u1)\n",
    "        push!(nodeids,u2)\n",
    "    end\n",
    "    nodeids = unique(nodeids)\n",
    "    Ntotinput = length(nodeids)\n",
    "    seekstart(fp)\n",
    "    \n",
    "    cnt = 0\n",
    "    links = zeros(Int64,Ltotinput,3)\n",
    "    for line in eachline( fp )\n",
    "    cnt += 1\n",
    "        line = rstrip(line, '\\n')\n",
    "        u = split(line, \" \")\n",
    "        #u = split(line, \"\\t\")\n",
    "        u1 = parse(Int64,u[1]) # convert string to number\n",
    "        u2 = parse(Int64,u[2])\n",
    "        u3 = parse(Float32,u[3])\n",
    "        links[cnt,1] = find(nodeids .== u1)[1]\n",
    "        links[cnt,2] = find(nodeids .== u2)[1]\n",
    "        links[cnt,3] = u3\n",
    "    end\n",
    "\n",
    "    links = labeledsimplegraph(links)\n",
    "    write(fpmeta, \"number of vertices (input): $(Ntotinput)\\n\")\n",
    "    write(fpmeta, \"number of edges (input, converted to simple graph): $(Int64(0.5*size(links,1)))\\n\\n\")\n",
    "\n",
    "    ######################\n",
    "    ####   Input parameters  ####\n",
    "    ######################\n",
    "    Nthreshold = round(Ntotinput/2)\n",
    "    plots = true\n",
    "    dc = true # degree-correction\n",
    "    priorlearning = true\n",
    "    learning = true\n",
    "    alluvial = true\n",
    "    Barray = [2:1:3;]\n",
    "    Bsize = length(Barray)\n",
    "    Bmax = maximum(Barray)\n",
    "    Bmin = minimum(Barray)\n",
    "    itrmax = 512\n",
    "    learningrate = 0.3\n",
    "    BPconvthreshold = 0.000001\n",
    "    samples = 5\n",
    "    REDalpha = 1 # negative edges = 1, neutral edges = 2, negative edges = 3\n",
    "    REDfrac = 0.5 # Fraction of edges that are modified to the neutral edges.\n",
    "    assortativity = [\"d\",\"a\"]\n",
    "    ######################\n",
    "    ######################\n",
    "    \n",
    "    A = sparse(links[:,1],links[:,2],ones(size(links,1)),Ntotinput,Ntotinput)\n",
    "    nb = Array[]\n",
    "    row = rowvals(A)\n",
    "    for j = 1:Ntotinput\n",
    "        push!(nb,Int64[row[i] for i in nzrange(A,j)])\n",
    "    end\n",
    "    cc = DFS(nb,1) # Assume node 1 belongs to the connected component\n",
    "    println(\"connected component identified...\")\n",
    "    (Ntot,links) = LinksConnected(links,Ntotinput,cc)\n",
    "    println(\"vertices & edges updated... : N = $(Ntot) 2L = $(size(links,1))\")\n",
    "    if Ntot != Ntotinput\n",
    "        println(\"Input graph is NOT a connected graph!\")\n",
    "    end\n",
    "    \n",
    "    degreeprofile(links,Ntot)\n",
    "    \n",
    "    Larray = Int64[]\n",
    "    links= sortrows(links, by=x->x[3])\n",
    "    prev = links[1,3]\n",
    "    Lval = 0\n",
    "    for ij = 1:size(links,1)\n",
    "        if links[ij,1] > links[ij,2]\n",
    "            continue\n",
    "        end\n",
    "        if links[ij,3] == prev\n",
    "            Lval += 1\n",
    "        else\n",
    "            push!(Larray,Lval)\n",
    "            prev = links[ij,3]\n",
    "            Lval = 1\n",
    "        end\n",
    "    end\n",
    "    push!(Larray,Lval)\n",
    "    Ltot = sum(Larray)\n",
    "    G = length(Larray) # Number of labels\n",
    "    \n",
    "    # Random Edge Discarding\n",
    "    if REDfrac != 0\n",
    "        (links,Larray) = RandomEdgeDiscarding(Ntot,links,G,Larray,REDalpha,REDfrac)\n",
    "        G = G + 1 # Neutral edges are added.\n",
    "        fpREDedgeslist = open(\"REDedgelist_$(dataset).txt\",\"w\")\n",
    "        for ij = 1:size(links,1)\n",
    "            i = nodeids[links[ij,1]]\n",
    "            j = nodeids[links[ij,2]]\n",
    "            if i > j\n",
    "                continue\n",
    "            end\n",
    "            \n",
    "            write(fpREDedgeslist, \"$(i) $(j) $(links[ij,3])\\n\")\n",
    "        end\n",
    "        close(fpREDedgeslist)\n",
    "    end\n",
    "    \n",
    "    blockprev = zeros(Ntot,1)\n",
    "    assignment = zeros(Int64,Ntot,Bsize+1) # 1st column is the node label, but B starts from 2\n",
    "    assignment[:,1] = nodeids #collect(1:Ntot)\n",
    "    BwithCVBP = Bmax\n",
    "    BwithCVGP = Bmax\n",
    "    CVBPopt = 1000000\n",
    "    CVGPopt = 1000000\n",
    "    write(fpmeta, \"Total numbmer of vertices (giant component): $(Ntot)\\n\")\n",
    "    write(fpmeta, \"Total numbmer of edges (giant component): $(Ltot)\\n\")\n",
    "    write(fpmeta, \"Numbmer of edges of each type (giant component): $(Larray)\\n\\n\")\n",
    "    write(fpmeta, \"Max number of iteration = $(itrmax)\\n\")\n",
    "    write(fpmeta, \"BP convergence threshold = $(BPconvthreshold)\\n\")\n",
    "    write(fpmeta, \"degree correction: $(dc)\\n\")\n",
    "    write(fpmeta, \"learning rate: $(learningrate)\\n\")\n",
    "    write(fpmeta, \"Label for Random Edge Discarding: $(REDalpha)\\n\")\n",
    "    write(fpmeta, \"Fraction of edges that are discarded (neutralized): $(REDfrac)\\n\")\n",
    "    write(fpmeta, \"Number of initial states = $(samples)\\n\\n\")\n",
    "\n",
    "    fpAssessment = open(\"assessment_$(dataset).txt\",\"w\")\n",
    "    fpPartition = open(\"assignment_$(dataset).txt\",\"w\")\n",
    "    \n",
    "    nullerror = UniformGraphError(links,Ntot,Larray,dc,G,Ltot,REDfrac)\n",
    "    write(fpmeta, \"Prediction error for q = 1 = $(nullerror)\\n\\n\")\n",
    "    \n",
    "    FEvec = zeros(Bsize)\n",
    "    CVBayesvec = zeros(Bsize,2)\n",
    "    CVGPvec = zeros(Bsize,2)\n",
    "    CVGTvec = zeros(Bsize,2)\n",
    "    CVMAPvec = zeros(Bsize,2)\n",
    "    grDict = Dict()\n",
    "    affinityDict = Dict() # [bb][alpha] -> B-by-B matrix\n",
    "    FEsDict = Dict()\n",
    "    \n",
    "    for bb = 1:Bsize\n",
    "        B = Barray[bb]\n",
    "        println(\"B = $(B)\")\n",
    "        FEs = zeros(samples,1)\n",
    "        CVBPs = zeros(samples,1)\n",
    "        CVGPs = zeros(samples,1)\n",
    "        CVGTs = zeros(samples,1)\n",
    "        CVMAPs = zeros(samples,1)\n",
    "        varCVBPs = zeros(samples,1)\n",
    "        varCVGPs = zeros(samples,1)\n",
    "        varCVGTs = zeros(samples,1)\n",
    "        varCVMAPs = zeros(samples,1)\n",
    "        FEmin = 100000\n",
    "        itrnumopt = 0\n",
    "        PSIopt = zeros(Ntot,B)\n",
    "        gropt = zeros(1,B)\n",
    "        affinityopt = Dict()\n",
    "\n",
    "        sm = 0\n",
    "        convfail = 0\n",
    "        while sm < samples\n",
    "            Omega = 1/B\n",
    "            (gr,affinity,PSI,FE,CVBayes,CVGP,CVGT,CVMAP,varCVBayes,varCVGP,varCVGT,varCVMAP,cnv,itrnum) = EM(Ntot,Larray,B,G,links,itrmax,BPconvthreshold,learning,priorlearning,dc,learningrate,REDfrac,assortativity,Omega)\n",
    "\n",
    "            if cnv == false\n",
    "                #=\n",
    "                if convfail < 3\n",
    "                    convfail += 1\n",
    "                    println(\"try again...\")\n",
    "                    continue\n",
    "                else\n",
    "                    println(\"BP does not converge.... : Raise itrnum or/and BPconv.\")\n",
    "                    #break\n",
    "                end\n",
    "                =#\n",
    "                println(\"try again...\")\n",
    "                continue\n",
    "            end\n",
    "            sm += 1\n",
    "\n",
    "            FEs[sm] = FE\n",
    "            CVBPs[sm] = CVBayes\n",
    "            CVGPs[sm] = CVGP\n",
    "            CVGTs[sm] = CVGT\n",
    "            CVMAPs[sm] = CVMAP\n",
    "            varCVBPs[sm] = varCVBayes\n",
    "            varCVGPs[sm] = varCVGP\n",
    "            varCVGTs[sm] = varCVGT\n",
    "            varCVMAPs[sm] = varCVMAP                \n",
    "            if FE < FEmin\n",
    "                FEmin = FE\n",
    "                itrnumopt = itrnum\n",
    "                PSIopt = PSI\n",
    "                gropt = gr\n",
    "                affinityopt = affinity\n",
    "            end\n",
    "        end # while sample loop\n",
    "\n",
    "        (PSIopt,gropt,affinityopt) = RelabelPSI(PSIopt,gropt,affinityopt,G) # Sort the Assignment\n",
    "        \n",
    "        # standard errors of CVs\n",
    "        SECVBayes = sqrt(varCVBPs[findmin(CVBPs)[2]]/Ltot)\n",
    "        SECVGP = sqrt(varCVGPs[findmin(CVGPs)[2]]/Ltot)\n",
    "        SECVGT = sqrt(varCVGTs[findmin(CVGTs)[2]]/Ltot)\n",
    "        SECVMAP = sqrt(varCVMAPs[findmin(CVMAPs)[2]]/Ltot)\n",
    "        \n",
    "        FEvec[bb] = minimum(FEs)\n",
    "        CVBayesvec[bb,1] = minimum(CVBPs)\n",
    "        CVBayesvec[bb,2] = SECVBayes\n",
    "        CVGPvec[bb,1] = minimum(CVGPs)\n",
    "        CVGPvec[bb,2] = SECVGP\n",
    "        CVGTvec[bb,1] = minimum(CVGTs)\n",
    "        CVGTvec[bb,2] = SECVGT\n",
    "        CVMAPvec[bb,1] = minimum(CVMAPs)\n",
    "        CVMAPvec[bb,2] = SECVMAP\n",
    "        grDict[bb] = gropt\n",
    "        affinityDict[bb] = affinityopt\n",
    "        FEsDict[bb] = FEs\n",
    "        if minimum(CVBPs) < CVBPopt\n",
    "            CVBPopt = minimum(CVBPs)\n",
    "            BwithCVBP = B\n",
    "        end        \n",
    "        if minimum(CVGPs) < CVGPopt\n",
    "            CVGPopt = minimum(CVGPs)\n",
    "            BwithCVGP = B\n",
    "        end        \n",
    "\n",
    "        (maxPSIval, ind) = findmax(PSIopt,2)\n",
    "        block = ind2sub((Ntot,B),vec(ind))[2]\n",
    "        assignment[:,bb+1] = block # 1st column is the node label, but B starts from 2\n",
    "        actualB = length(unique(vec(block)))\n",
    "        write(fpmeta, \"q = $(B): actual q = $(actualB), number of iteration = $(itrnumopt) \\n\")\n",
    "        \n",
    "        if alluvial == true\n",
    "            AlluvialDiagram(B,block,maxPSIval,nodeids)\n",
    "            AssignmentsWithSignificance(B,block,maxPSIval,nodeids)\n",
    "            AssignmentProbs(B,nodeids,PSIopt)\n",
    "        end\n",
    "    end # B-loop\n",
    "\n",
    "    write(fpmeta, \"\\n\")\n",
    "    write(fpmeta, \"CV(Bayes Prediction): q* = $(BwithCVBP) (This may not be parsimonius.)\\n\")\n",
    "    write(fpmeta, \"CV(Gibbs Prediction): q* = $(BwithCVGP) (This may not be parsimonius.)\\n\")\n",
    "    for i = 1:Ntot\n",
    "        write(fpPartition, join(assignment[i,:], \" \")*\"\\n\")\n",
    "    end\n",
    "    \n",
    "    # OUTPUT RESULTS :::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "    write(fpAssessment, \"Bethe free energy:\\n\")\n",
    "    write(fpAssessment, \"(q, assessed value)\\n\")\n",
    "    for bb = 1:Bsize\n",
    "        B = Barray[bb]\n",
    "        write(fpAssessment, string(B)*\" $(FEvec[bb])\\n\")\n",
    "    end\n",
    "    write(fpAssessment, \"\\nBayes prediction error:\\n\")\n",
    "    write(fpAssessment, \"(q, assessed value, standard error)\\n\")\n",
    "    for bb = 1:Bsize\n",
    "        B = Barray[bb]\n",
    "        write(fpAssessment, \"$(B) $(CVBayesvec[bb,1]) $(CVBayesvec[bb,2])\\n\")\n",
    "    end\n",
    "    write(fpAssessment, \"\\nGibbs prediction error:\\n\")\n",
    "    write(fpAssessment, \"(q, assessed value, standard error)\\n\")\n",
    "    for bb = 1:Bsize\n",
    "        B = Barray[bb]\n",
    "        write(fpAssessment,\"$(B) $(CVGPvec[bb,1]) $(CVGPvec[bb,2])\\n\")\n",
    "    end\n",
    "    write(fpAssessment, \"\\nGibbs training error:\\n\")\n",
    "    write(fpAssessment, \"(q, assessed value, standard error)\\n\")\n",
    "    for bb = 1:Bsize\n",
    "        B = Barray[bb]\n",
    "        write(fpAssessment,\"$(B) $(CVGTvec[bb,1]) $(CVGTvec[bb,2])\\n\")\n",
    "    end\n",
    "    write(fpAssessment, \"\\nGibbs prediction error (MAP estimate):\\n\")\n",
    "    write(fpAssessment, \"(q, assessed value, standard error)\\n\")\n",
    "    for bb = 1:Bsize\n",
    "        B = Barray[bb]\n",
    "        write(fpAssessment,\"$(B) $(CVMAPvec[bb,1]) $(CVMAPvec[bb,2])\\n\")\n",
    "    end\n",
    "    write(fpAssessment, \"\\nModule sizes:\\n\")\n",
    "    for bb = 1:Bsize\n",
    "        B = Barray[bb]\n",
    "        write(fpAssessment,\"q = $(B)\\n\")\n",
    "        write(fpAssessment,\"$(grDict[bb])\\n\")\n",
    "    end\n",
    "    write(fpAssessment, \"\\nAffinity matrix of each alpha \\n\")\n",
    "    for bb = 1:Bsize\n",
    "        B = Barray[bb]\n",
    "        write(fpAssessment,\"q = $(B)\\n\")\n",
    "        write(fpAssessment,\"$(affinityDict[bb])\\n\")\n",
    "    end\n",
    "    #::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "    \n",
    "    # PLOT RESULTS .................................................\n",
    "    if plots == true\n",
    "        x = Barray\n",
    "        y0 = FEvec\n",
    "        y1 = CVBayesvec[:,1]\n",
    "        y1error = CVBayesvec[:,2]\n",
    "        y2 = CVGPvec[:,1]\n",
    "        y2error = CVGPvec[:,2]\n",
    "        y3 = CVGTvec[:,1]\n",
    "        y3error = CVGTvec[:,2]\n",
    "        y4 = CVMAPvec[:,1]\n",
    "        y4error = CVMAPvec[:,2]    \n",
    "        PlotAssessments(x,y0,y1,y1error,y2,y2error,y3,y3error,y4,y4error,dataset)\n",
    "        \n",
    "        PlotAffinityMatrixLBM(Bsize,grDict,affinityDict,dataset,REDfrac)\n",
    "        PlotCumulativeFEdistribution(Bsize,FEsDict,dataset)\n",
    "    end\n",
    "    #..........................................................................\n",
    "\n",
    "    close(fpAssessment)\n",
    "    close(fpPartition)\n",
    "    \n",
    "end # open\n",
    "close(fpmeta)\n",
    "\n",
    "# Data Assumption:\n",
    "# The input graph is assumed to be connected. Although the giant component is extracted, the nodeids will no longer be correct if Ntotinput != Ntot.\n",
    "# The last label has the most assortative structure, while the first label has the most disassortative structure.\n",
    "\n",
    "# About node ids\n",
    "# step1: Node ids are extracted from the edgelist. (unique, but NOT successive)\n",
    "# step2: Relabel the original edgelist; if nodeid = [15, 1, 30, ...], then node 15 will be converted to node 1, node 1 will be converted to node 2, and so on. \n",
    "# Therefore, the module assignments inside the EM algorithm is of this converted node labels.\n",
    "# step3: When the assignment data (assignment.txt and .smap files) is generated, the node labels need to be converted back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
